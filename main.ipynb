{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pagination\n",
    "for page in range(1, 416):\n",
    "    # Browser options\n",
    "    driver_path = \"chromedriver.exe\"\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-infobars\")\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_experimental_option(\"prefs\", {\"profile.default_content_setting_values.notifications\": 2}) \n",
    "    driver = webdriver.Chrome(chrome_options=options, executable_path=driver_path)\n",
    "    driver.set_window_size(1024, 600)\n",
    "    driver.maximize_window()\n",
    "    url = f'https://www.zapimoveis.com.br/venda/apartamentos/?pagina={page}&transacao=Venda&tipo=Im%C3%B3vel%20usado&tipoUnidade=Residencial,Apartamento'\n",
    "    driver.get(url)\n",
    "    time.sleep(1.5)\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, f'/html/body/div[2]/div/div/button').click()\n",
    "    except: \n",
    "        pass\n",
    "    time.sleep(1.5)\n",
    "    xpath_number = 1\n",
    "\n",
    "    title_list = []\n",
    "    cond_list = []\n",
    "    iptu_list = []\n",
    "    address_list = []\n",
    "    price_list = []\n",
    "    bedrooms_list = []\n",
    "    bathrooms_list = []\n",
    "    garage_list = []\n",
    "    area_list = []\n",
    "    floor_list = []\n",
    "    items_list = []\n",
    "    description_list = []\n",
    "    url_list = []\n",
    "    \n",
    "    # click anouncements\n",
    "    for i in range(1,25):\n",
    "        try:\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, f'/html/body/div[2]/div/div/button').click()\n",
    "            except: \n",
    "                pass\n",
    "            # click in anouncement\n",
    "            driver.find_element(By.XPATH, f'/html/body/main/section[1]/div[1]/div[3]/section/div/div[{xpath_number}]/div/div[1]/div[2]').click()\n",
    "            time.sleep(1.5)\n",
    "        \n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "            url = driver.current_url\n",
    "            url_list.append(url)            \n",
    "\n",
    "            try:\n",
    "                title = driver.find_element(By.XPATH, '/html/body/main/div/section/article[1]/h1/strong')\n",
    "                soup = BeautifulSoup(title.get_attribute('outerHTML'), 'html.parser')\n",
    "                title_list.append(soup.text)\n",
    "            except:\n",
    "                title_list.append('Not informed')\n",
    "\n",
    "            try:\n",
    "                cond = driver.find_element(By.XPATH, '/html/body/main/div/section/article[1]/div[2]/div[1]/div[2]/div/ul/li[1]/span')\n",
    "                soup = BeautifulSoup(cond.get_attribute('outerHTML'), 'html.parser')\n",
    "                cond_list.append(soup.text)\n",
    "            except:\n",
    "                cond_list.append('Not informed')\n",
    "\n",
    "            try:\n",
    "                iptu = driver.find_element(By.XPATH, '/html/body/main/div/section/article[1]/div[2]/div[1]/div[2]/div/ul/li[2]/span')\n",
    "                soup = BeautifulSoup(iptu.get_attribute('outerHTML'), 'html.parser')\n",
    "                iptu_list.append(soup.text)\n",
    "            except:\n",
    "                iptu_list.append('Not informed')\n",
    "\n",
    "            try:\n",
    "                address = driver.find_element(By.XPATH, '/html/body/main/div/section/article[1]/div[2]/div[1]/div[1]/p/button/span[2]')\n",
    "                soup = BeautifulSoup(address.get_attribute('outerHTML'), 'html.parser')\n",
    "                address_list.append(soup.text)    \n",
    "            except:\n",
    "                address_list.append('Address not informed')\n",
    "\n",
    "            try:    \n",
    "                price = driver.find_element(By.XPATH, '/html/body/main/div/section/article[1]/div[2]/div[1]/div[2]/div/div[1]/ul/li/strong')\n",
    "                soup = BeautifulSoup(price.get_attribute('outerHTML'), 'html.parser')\n",
    "                price_list.append(soup.text)\n",
    "            except:\n",
    "                price_list.append('Price not informed')\n",
    "\n",
    "            try:\n",
    "                area = driver.find_element(By.XPATH, f\"//span[@itemprop='floorSize']\")\n",
    "                soup = BeautifulSoup(area.get_attribute('outerHTML'), 'html.parser')\n",
    "                area_list.append(soup.text)\n",
    "            except:\n",
    "                area_list.append('Not informed')\n",
    "\n",
    "            try:\n",
    "                bedrooms = driver.find_element(By.XPATH, f\"//span[@itemprop='numberOfRooms']\")\n",
    "                soup = BeautifulSoup(bedrooms.get_attribute('outerHTML'), 'html.parser')\n",
    "                bedrooms_list.append(soup.text)\n",
    "            except:\n",
    "                bedrooms_list.append('Not informed')\n",
    "\n",
    "            try:\n",
    "                garage = driver.find_element(By.CLASS_NAME, 'feature__item.text-regular.js-parking-spaces')\n",
    "                soup = BeautifulSoup(garage.get_attribute('outerHTML'), 'html.parser')\n",
    "                garage_list.append(soup.text)\n",
    "            except:\n",
    "                garage_list.append('Not informed')\n",
    "\n",
    "            try:\n",
    "                bathrooms = driver.find_element(By.XPATH, f\"//span[@itemprop='numberOfBathroomsTotal']\")\n",
    "                soup = BeautifulSoup(bathrooms.get_attribute('outerHTML'), 'html.parser')\n",
    "                bathrooms_list.append(soup.text)\n",
    "            except:\n",
    "                bathrooms_list.append('Not informed')\n",
    "\n",
    "            try:\n",
    "                floor = driver.find_element(By.XPATH, f\"//span[@itemprop='floorLevel']\")\n",
    "                soup = BeautifulSoup(floor.get_attribute('outerHTML'), 'html.parser')\n",
    "                floor_list.append(soup.text)\n",
    "            except:\n",
    "                floor_list.append('Floor not informed')\n",
    "\n",
    "            try:\n",
    "                temp_list = []\n",
    "                items = driver.find_elements(By.CLASS_NAME, 'amenities__list')\n",
    "                for item in items:\n",
    "                    soup = BeautifulSoup(item.get_attribute('outerHTML'), 'html.parser')\n",
    "                    temp_list.append(soup.text)\n",
    "                \n",
    "                items_list.append(temp_list)\n",
    "            except:\n",
    "                items_list.append('Features not informed')\n",
    "\n",
    "            try:\n",
    "                description = driver.find_element(By.CLASS_NAME, 'amenities__description.text-regular.text-margin-zero')\n",
    "                soup = BeautifulSoup(description.get_attribute('outerHTML'), 'html.parser')\n",
    "                description_list.append(soup.text)    \n",
    "            except:\n",
    "                description_list.append('Description not informed')\n",
    "            # close tab\n",
    "            driver.close()\n",
    "            time.sleep(1.5)\n",
    "\n",
    "            # switch to main tab\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "            \n",
    "            time.sleep(1.5)\n",
    "            xpath_number += 1\n",
    "            \n",
    "\n",
    "        except:\n",
    "            xpath_number += 1\n",
    "            print(f'Anouncement: {xpath_number} not found')   \n",
    "\n",
    "    df = pd.DataFrame({'Title': title_list, \n",
    "                        'Cond': cond_list, \n",
    "                        'IPTU': iptu_list, \n",
    "                        'Address': address_list, \n",
    "                        'Price': price_list, \n",
    "                        'Bedrooms': bedrooms_list, \n",
    "                        'Bathrooms': bathrooms_list, \n",
    "                        'Garage': garage_list, \n",
    "                        'Area': area_list, \n",
    "                        'Floor': floor_list, \n",
    "                        'Features': items_list, \n",
    "                        'Description': description_list,\n",
    "                        'Url': url_list}).fillna('NaN')         \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df.to_csv('zapimoveisDB.csv', mode='a', sep=';')     \n",
    "    time.sleep(1.5)\n",
    "    driver.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39c5207e0ce1341ad898502cc592606dcf3036f0772b83709aba2273e6498e4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
